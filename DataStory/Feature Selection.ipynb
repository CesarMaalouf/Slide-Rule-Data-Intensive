{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy as sqla\n",
    "import numpy as np\n",
    "\n",
    "#import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = sqla.create_engine('postgresql://postgres:postgres@localhost:5432/TaxiData',echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_type\n",
       "USER-DEFINED           2\n",
       "bigint                 2\n",
       "character varying      2\n",
       "double precision     405\n",
       "integer               66\n",
       "interval               7\n",
       "text                   1\n",
       "Name: data_type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columntypelist=pd.read_sql_query(\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = 'lotsofdata';\", engine)\n",
    "\n",
    "columntypelist.set_index('column_name',inplace=True)\n",
    "\n",
    "\n",
    "columntypelist.groupby(['data_type'])['data_type'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbercolumns=columntypelist[(columntypelist['data_type']=='double precision')|(columntypelist['data_type']=='bigint')|(columntypelist['data_type']=='integer')|(columntypelist.index=='fipscodes')]['data_type']\n",
    "\n",
    "numbercolumns.index=numbercolumns.index.str.strip()\n",
    "\n",
    "numbercolumns=numbercolumns[numbercolumns.index.str.find(' ')==-1].index.tolist()\n",
    "\n",
    "len(numbercolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#columnstring=\"'\"+\"', '\".join(numbercolumns)+\"'\"\n",
    "columnstring='\"'+'\", \"'.join(numbercolumns)+'\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full=pd.read_sql_query('SELECT '+columnstring + ' FROM lotsofdata',engine).set_index('fipscodes')\n",
    "full=full[full['totalpopulation']>=1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yname='twentythirteen_full_count_pc'\n",
    "dropoffitems=['abridged2013ycdrpoffpc','counts','abridged2013ycdrpoff',\\\n",
    "              'driver_income_standard_dev_resid', 'twentythirteen_full_count_pc',\\\n",
    "              'time_dif_derived_approxcount_error', 'time_dif_derived_approxcount',\\\n",
    "              'twentythirteen_full_count', 'driver_income_anscombe_resid']\n",
    "full.drop([i for i in dropoffitems if i is not Yname],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full.replace(np.inf, np.nan,inplace=True)\n",
    "full.dropna(axis='columns',how='all',inplace=True)\n",
    "full.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full.drop_duplicates(inplace=True)\n",
    "full=full.T.drop_duplicates(keep='last').T\n",
    "pcfull=full\n",
    "#pcfull.replace({'totalpopulation':{0:np.nan}},inplace=True)\n",
    "#pcfull.dropna().shape\n",
    "Y=pcfull[Yname]\n",
    "pcfull=pcfull.divide(full['totalpopulation'],axis='index')\n",
    "#These were already per-capita type data columns, or shouldn't be per-capita\n",
    "#pcfull['nondrivercommuterrat']=((pcfull['MOGE001']-pcfull['MOGE011'])/pcfull['MOGE001'])\n",
    "pcfull['MRUE001']=full['MRUE001']\n",
    "pcfull['MRUM001']=full['MRUM001']\n",
    "pcfull['totalpopulation']=full['totalpopulation']\n",
    "pcfull['boro_int_code']=full['boro_int_code']\n",
    "pcfull['nondrivercomrat']=full['nondrivercomrat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The census/ACS data columns all are given a 7 letter/number code. The data comes with \"code books\", text files with descriptions of the data and what the codes mean. The function below grabs the one-line descriptions that go with each code, giving a nice, brief description of what each code means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "codebookpath=os.path.expanduser('~/Documents/TaxiTripData/TIGERFiles/nhgis_codebooks')\n",
    "\n",
    "def searchcodebook(code,path=codebookpath):\n",
    "    import subprocess\n",
    "    command='grep -r -h -m 1 '+code+' '+path+'*'\n",
    "    try:\n",
    "        grepstring=subprocess.check_output(command,shell=True)\n",
    "        return grepstring[grepstring.find(code)+len(code)+1:grepstring.find('\\r')].strip()\n",
    "    except subprocess.CalledProcessError:\n",
    "        return code\n",
    "\n",
    "codebookdict=pcfull.columns.to_series().apply(searchcodebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MRUE001    Per capita income in the past 12 months (in 20...\n",
       "MRUM001    Per capita income in the past 12 months (in 20...\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codebookdict[((codebookdict.str.find('capita'))!=-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That makes sure I didn't miss any per-capita data columns that I didn't know about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection for all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MRUM001    Per capita income in the past 12 months (in 20...\n",
       "MRUE001    Per capita income in the past 12 months (in 20...\n",
       "MOGE101                                               Walked\n",
       "MOKE010                               8:30 a.m. to 8:59 a.m.\n",
       "MOGE083    Public transportation (excluding taxicab): Str...\n",
       "MOGE105                             Walked: 20 to 24 minutes\n",
       "MOJE016                                              Taxicab\n",
       "MOGE104                             Walked: 15 to 19 minutes\n",
       "MOGE085    Public transportation (excluding taxicab): Str...\n",
       "MOGE103                             Walked: 10 to 14 minutes\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import feature_selection\n",
    "\n",
    "featureselect=feature_selection.SelectKBest(feature_selection.f_regression)\n",
    "featureselect.fit(pcfull.drop(Yname,axis=1),Y)\n",
    "pcfeaturescores=pd.Series(featureselect.pvalues_)\n",
    "pcfeaturescores.index=pcfull.drop(Yname,axis=1).columns\n",
    "pcfeaturescores.sort_values(ascending=True,inplace=True)\n",
    "\n",
    "#codebookdict[pcfeaturescores.iloc[:10].index].tolist()\n",
    "codebookdict[pcfeaturescores.iloc[:10].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 4th letter in the codes correspond to whether or not the code is an estimate of the value (E) or a margin of error for that estimate (M). Apparently the margin of error for per capita income, MRUM001, is better correlated with drop-offs per capita than the estimate itself. Since it seems drop-offs have a pretty significant power relationship to income and are not linear, I'm not about to look into that too deeply. Also, apparently the number of commuters who walk to work is pretty predictive too. \n",
    "\n",
    "However, it does look like the feature that I first had the instinct to look at, per-capita income, is relatively predictive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "correlm=pcfull[pcfeaturescores.iloc[:3].index.tolist()+[Yname,'MOJE016']]\n",
    "#correlm['logWalked']=np.log(correlm['MOGE101'])\n",
    "correlm['logIncome']=np.log(correlm['MRUE001'])\n",
    "correlm['logDropOffs']=np.log(correlm[Yname])\n",
    "corr_matrix = np.corrcoef(correlm.T)\n",
    "sm.graphics.plot_corr(corr_matrix, xnames=correlm.columns.tolist(),cmap=plt.cm.get_cmap('viridis'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection for the unexplained subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I had already explained a fair bit of the data, I'm going to focus on finding features that might better explain the unexplained data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Note that I dropped an obvious outlier. \n",
    "#It's right on the border between the 0.8 boundry I chose \n",
    "#It lies right on the income line, so maybe if I adjust my boundry a bit it can be explained through income.\n",
    "comd=0.8\n",
    "bsub=pcfull[(pcfull['nondrivercomrat']<=comd)]\n",
    "Ysub=Y[(pcfull['nondrivercomrat']<=comd)]\n",
    "bsub[Yname]=Ysub\n",
    "featureselect=feature_selection.SelectKBest(feature_selection.f_regression)\n",
    "featureselect.fit(bsub.drop(Yname,axis=1).drop(Ysub.idxmax()),Ysub.drop(Ysub.idxmax()))\n",
    "pcfeaturescores=pd.Series(featureselect.pvalues_)\n",
    "pcfeaturescores.index=bsub.drop(Yname,axis=1).columns\n",
    "pcfeaturescores.sort_values(ascending=True,inplace=True)\n",
    "#codebookdict[pcfeaturescores.iloc[:10].index].tolist()\n",
    "#codebookdict[pcfeaturescores.iloc[:10].index]\n",
    "\n",
    "zip(pcfeaturescores.iloc[:15].index.tolist(),codebookdict[pcfeaturescores.iloc[:15].index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that public transportation use is pretty predictive of taxicab use, with the time it takes for commutes on public transit also playing a role. It might be a good idea to try to create a public transit travel time by combining the public transit travel times to various hot-spots using Google maps.\n",
    "\n",
    "In the mean time, I'm going to focus on the general public transit usage numbers, at approach the timed ones later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General public transit usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three general public transit features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genpublictransit=['MOJE013','MOGE081','MOGE061']\n",
    "zip(genpublictransit,codebookdict[genpublictransit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these is measuring pretty similar things. I believe that the first two are essentially subsets of the third."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "corr_matrix = np.corrcoef(bsub[genpublictransit].T)\n",
    "sm.graphics.plot_corr(corr_matrix, xnames=bsub[genpublictransit].columns.tolist(),cmap=plt.cm.get_cmap('viridis'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the first two are nearly identical, and I actually think that the difference between the two could just be that people don't understand what a streetcar or trolley car is, as I don't know of any in NYC and the trolley car counts look pretty randomly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "labelx='MOJE013'\n",
    "justgood=bsub[[labelx,Yname]]\n",
    "justgood.replace(np.inf,np.nan, inplace=True)\n",
    "justgood.replace(0,np.nan,inplace=True)\n",
    "justgood.dropna(inplace=True)\n",
    "plt.autoscale(enable=False)\n",
    "plt.scatter(justgood[labelx],justgood[Yname],alpha=0.65)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel(labelx+\": \"+codebookdict[labelx])\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "labelx='MOGE061'\n",
    "justgood=bsub[[labelx,Yname]]\n",
    "justgood.replace(np.inf,np.nan, inplace=True)\n",
    "justgood.replace(0,np.nan,inplace=True)\n",
    "justgood.dropna(inplace=True)\n",
    "plt.autoscale(enable=False)\n",
    "plt.scatter(justgood[labelx],justgood[Yname],alpha=0.65)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel(labelx+\": \"+codebookdict[labelx])\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would guess that most of the extra predictive power of the just subway public transit comes from the little separate chunk off on the lower left of the plot, shown in red below (I just used a line I eyeballed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "labelx='MOJE013'\n",
    "justgood=bsub[[labelx,Yname]]\n",
    "justgood.replace(np.inf,np.nan, inplace=True)\n",
    "justgood.replace(0,np.nan,inplace=True)\n",
    "justgood.dropna(inplace=True)\n",
    "plt.autoscale(enable=False)\n",
    "linx=np.linspace(justgood[labelx].min(),justgood[labelx].max())\n",
    "cllinx=np.linspace(0.0,0.1)\n",
    "justgood['mydivision']=np.sign(-(justgood[Yname]-10**(-16*justgood[labelx]-1.4)))\n",
    "plt.scatter(justgood[labelx],justgood[Yname],alpha=0.5,c=justgood['mydivision'],cmap=plt.cm.get_cmap('jet'))\n",
    "#plt.plot(linx,np.exp(fit.params[labelx]*linx+fit.params['const']),color='red',alpha=0.1)\n",
    "plt.plot(cllinx,10**(-16*cllinx-1.4),color='black',alpha=0.8)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel(labelx+\": \"+codebookdict[labelx])\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I tried to get a clustering algorithm to automate this for me, but I can't say I had much success. I'd like to figure out how to do that properly though, so I detailed my struggles at the bottom of this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cluster makes this data less than ideal for linear regression, as the regression line will end up mostly connecting the dots between the two clusters, while ideally we would \n",
    "\n",
    "There's a good reason for this cluster's existence: Staten Island has no subway connections to the Manhattan business district, so public transit users there will generally not be taking the subway. This also makes Staten Island demographically very different from the rest of NYC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "borocodes=pd.read_sql_query(\"SELECT int, name FROM testborocodedict\", engine).set_index('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "borocodes['name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "plt.figure(figsize=[6,6])\n",
    "labelx='MOJE013'\n",
    "justgood=bsub[[labelx,Yname,'boro_int_code']]\n",
    "justgood.replace(np.inf,np.nan, inplace=True)\n",
    "justgood.replace(0,np.nan,inplace=True)\n",
    "justgood.dropna(inplace=True)\n",
    "plt.autoscale(enable=False)\n",
    "a=plt.scatter(justgood[labelx].iloc[::-1],justgood[Yname].iloc[::-1],c=justgood['boro_int_code'].iloc[::-1],cmap=plt.cm.get_cmap('jet'),alpha=0.65)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel(labelx+\": \"+codebookdict[labelx])\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "cbar=plt.colorbar(a,ticks=borocodes.index.tolist(),orientation='horizontal')\n",
    "cbar.ax.set_xticklabels(borocodes['name'].tolist())\n",
    "cbar.set_label(\"Boro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of bothering with the subway specific data, we can probably do a better job by just dealing with the Staten Island data separately. Since the drop-offs there tend to be so low, I would guess that it would be best to just assign that data the Staten Island average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Staten Island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Note that I dropped an obvious outlier. \n",
    "#It's right on the border between the 0.8 boundry I chose \n",
    "#It lies right on the income line, so maybe if I adjust my boundry a bit it can be explained through income.\n",
    "comd=0.8\n",
    "bsub=pcfull[(pcfull['nondrivercomrat']<=comd)&(pcfull['boro_int_code']!=5)]\n",
    "Ysub=Y[(pcfull['nondrivercomrat']<=comd)&(pcfull['boro_int_code']!=5)]\n",
    "bsub[Yname]=Ysub\n",
    "featureselect=feature_selection.SelectKBest(feature_selection.f_regression)\n",
    "featureselect.fit(bsub.drop(Yname,axis=1).drop(Ysub.idxmax()),Ysub.drop(Ysub.idxmax()))\n",
    "pcfeaturescores=pd.Series(featureselect.pvalues_)\n",
    "pcfeaturescores.index=bsub.drop(Yname,axis=1).columns\n",
    "pcfeaturescores.sort_values(ascending=True,inplace=True)\n",
    "#codebookdict[pcfeaturescores.iloc[:10].index].tolist()\n",
    "codebookdict[pcfeaturescores.iloc[:10].index]\n",
    "zip(pcfeaturescores.iloc[:15].index.tolist(),codebookdict[pcfeaturescores.iloc[:15].index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "plt.figure(figsize=[6,6])\n",
    "labelx='MOJE013'\n",
    "justgood=bsub[[labelx,Yname,'boro_int_code']]\n",
    "justgood.replace(np.inf,np.nan, inplace=True)\n",
    "justgood.replace(-np.inf,np.nan,inplace=True)\n",
    "justgood.replace(0.0,np.nan,inplace=True)\n",
    "justgood.dropna(inplace=True)\n",
    "#justgood=justgood[justgood['boro_int_code']==4]\n",
    "plt.autoscale(enable=False)\n",
    "a=plt.scatter(justgood[labelx].iloc[::-1],justgood[Yname].iloc[::-1],c=justgood['boro_int_code'].iloc[::-1],cmap=plt.cm.get_cmap('jet'),alpha=0.65)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel(labelx+\": \"+codebookdict[labelx])\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "cbar=plt.colorbar(a,ticks=borocodes.index.tolist(),orientation='horizontal')\n",
    "cbar.ax.set_xticklabels(borocodes['name'].tolist())\n",
    "cbar.set_label(\"Boro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#featindex=[pcfeaturescores.index[0],pcfeaturescores.index[3]]\n",
    "model=sm.OLS(np.log(justgood[Yname]),sm.add_constant(justgood[labelx],prepend=False))\n",
    "fit=model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty abysmal $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.figure(figsize=[6,6])\n",
    "labelx='MOJE013'\n",
    "justgood=bsub[[labelx,Yname,'boro_int_code']]\n",
    "justgood.replace(np.inf,np.nan, inplace=True)\n",
    "justgood.replace(-np.inf,np.nan,inplace=True)\n",
    "justgood.replace(0.0,np.nan,inplace=True)\n",
    "justgood.dropna(inplace=True)\n",
    "linx=np.linspace(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.autoscale(enable=False)\n",
    "a=plt.scatter(justgood[labelx].iloc[::-1],justgood[Yname].iloc[::-1],alpha=0.65)\n",
    "plt.plot(linx,np.exp(fit.params['const']+fit.params[labelx]*linx),alpha=0.8,color='red')\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel(labelx+\": \"+codebookdict[labelx])\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "#cbar=plt.colorbar(a,ticks=borocodes.index.tolist(),orientation='horizontal')\n",
    "#cbar.ax.set_xticklabels(borocodes['name'].tolist())\n",
    "#cbar.set_label(\"Boro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would say that this fit seems to be driven by the outliers and some high-leverage points, and that the main cluster isn't doesn't have a great fit going for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digression on looking for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig=sm.qqplot(fit.resid,line='45')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist=fit.resid.hist(alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats import outliers_influence\n",
    "\n",
    "influence=outliers_influence.OLSInfluence(fit)\n",
    "\n",
    "infframe=influence.summary_frame()\n",
    "\n",
    "outliers=infframe[np.abs(infframe['student_resid'])>3].index\n",
    "\n",
    "\n",
    "#\"' OR fipscodes = '\".join(outliers.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "highleverage=infframe[infframe['hat_diag']>(infframe['hat_diag'].mean()*3)].index\n",
    "#\"' OR fipscodes = '\".join(highleverage.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropout1=justgood.drop(outliers+highleverage)\n",
    "model=sm.OLS(np.log(dropout1[Yname]),sm.add_constant(dropout1[labelx],prepend=False))\n",
    "fit2=model.fit()\n",
    "fit2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now the fit really is abysmal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.figure(figsize=[6,6])\n",
    "labelx='MOJE013'\n",
    "justgood=bsub[[labelx,Yname,'boro_int_code']]\n",
    "justgood.replace(np.inf,np.nan, inplace=True)\n",
    "justgood.replace(-np.inf,np.nan,inplace=True)\n",
    "justgood.replace(0.0,np.nan,inplace=True)\n",
    "justgood.dropna(inplace=True)\n",
    "linx=np.linspace(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.autoscale(enable=False)\n",
    "a=plt.scatter(justgood.drop(outliers+highleverage)[labelx],justgood.drop(outliers+highleverage)[Yname],alpha=0.5,label='second fit points')\n",
    "plt.scatter(justgood.loc[outliers][labelx],justgood.loc[outliers][Yname],alpha=0.5,color='green',label='Outliers')\n",
    "plt.scatter(justgood.loc[highleverage][labelx],justgood.loc[highleverage][Yname],alpha=0.5,color='magenta',label='High leverage')\n",
    "plt.plot(linx,np.exp(fit.params['const']+fit.params[labelx]*linx),alpha=0.8,color='black',label='Initial fit, $R^2$='+str(round(fit.rsquared,2)),lw=2)\n",
    "plt.plot(linx,np.exp(fit2.params['const']+fit2.params[labelx]*linx),alpha=0.8,color='red',label='second fit, $R^2$='+str(round(fit2.rsquared,2)),lw=2)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel(labelx+\": \"+codebookdict[labelx])\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "#plt.legend(loc='lower right')\n",
    "#cbar=plt.colorbar(a,ticks=borocodes.index.tolist(),orientation='horizontal')\n",
    "#cbar.ax.set_xticklabels(borocodes['name'].tolist())\n",
    "#cbar.set_label(\"Boro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My question here is: I've removed the outliers from the previous fit, but that has changed the hat matrix, so we have outliers with the *new* fit still in there. Should I go through another round of outlier removal? I'm beating a dead horse; this fit sucks, so I'm not going to go on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "influence=outliers_influence.OLSInfluence(fit2)\n",
    "\n",
    "infframe2=influence.summary_frame()\n",
    "\n",
    "outliers2=infframe2[np.abs(infframe2['student_resid'])>3].index\n",
    "#print(\"' OR fipscodes = '\".join(outliers2.tolist()))\n",
    "highleverage=infframe[infframe['hat_diag']>(infframe['hat_diag'].mean()*3)].index\n",
    "#print(\"' OR fipscodes = '\".join(highleverage.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bsub.loc[outliers|highleverage]['nondrivercomrat'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be useful to adjust the non-driver commuter ratio boundary, as many of these outliers are pretty close to it. I'll look into that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time based public transit data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it seems like I should take a look at that time-based data, as things didn't work out too well with the general public transit data, though I did figure some things out with Staten Island. \n",
    "\n",
    "Just a reminder, these were the low p-value features (i.e. low probability that there is no relationship between the feature and dropoffs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip(pcfeaturescores.iloc[:15].index.tolist(),codebookdict[pcfeaturescores.iloc[:15].index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way we might create a measure of just the subway commute time would be adding together the rates of subway commuters for a given time frame, weighted by the mean of that time frame. Doing this, however, would just give us a linear combination of the public transit time features. Instead of putting that together myself, I can just put all the public transit time features into OLS, and it can figure out the linear combination itself. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PTtimerates=['MOGE0'+str(i) for i in xrange(82,91)]\n",
    "zip(PTtimerates,codebookdict[PTtimerates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "justgood=bsub[bsub['boro_int_code']!=5][PTtimerates+[Yname]]\n",
    "justgood[PTtimerates].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, individually, many of these probably wouldn't make very good features, as most of them are zero. However, I think that when we put them all together, we can get a measure of the amount of time that subway commutes take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "justgood=bsub[bsub['boro_int_code']!=5][PTtimerates+[Yname]]\n",
    "model3=sm.OLS(np.log(justgood[Yname]),sm.add_constant(justgood.drop(Yname,axis=1),prepend=False))\n",
    "fit3=model3.fit()\n",
    "fit3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#justgood['boro_int_code']=pcfull.loc[justgood.index]['boro_int_code']\n",
    "xdata=(fit3.params.drop('const')*justgood[PTtimerates]).sum(axis=1)\n",
    "#justgood.drop(justgood[Yname].idxmax(),inplace=True)\n",
    "#SI=justgood[justgood['boro_int_code']==5]\n",
    "#NSI=justgood[justgood['boro_int_code']!=5]\n",
    "plt.autoscale(enable=False)\n",
    "linx=np.linspace(xdata.min(),xdata.max())\n",
    "#plt.scatter(NSI[labelx],NSI[Yname],alpha=0.5)\n",
    "#plt.scatter(SI[labelx],SI[Yname],alpha=0.5,color='yellow')\n",
    "plt.scatter(xdata,justgood[Yname],alpha=0.4)\n",
    "plt.plot(linx,np.exp(linx+fit3.params['const']),color='red',alpha=0.8)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(xdata.min(),xdata.max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel('fitted public transit time based projection')\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "#plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timemidpoints=[5,12,17,22,27,32,39.5,52,np.nan,np.nan]\n",
    "plt.scatter(timemidpoints,fit3.params.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "influence=outliers_influence.OLSInfluence(fit3)\n",
    "\n",
    "infframe3=influence.summary_frame()\n",
    "\n",
    "outliers3=infframe3[np.abs(infframe3['student_resid'])>3].index\n",
    "#print(\"fipscodes = '\"+\"' OR fipscodes = '\".join(outliers3.tolist())+\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full.loc[outliers3][['nondrivercomrat','boro_int_code']].sort_values(by=['boro_int_code','nondrivercomrat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model3=sm.OLS(np.log(justgood.drop(outliers3)[Yname]),sm.add_constant(justgood.drop(outliers3)[PTtimerates],prepend=False))\n",
    "fit3=model3.fit()\n",
    "fit3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit3.resid[outliers3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#justgood['boro_int_code']=pcfull.loc[justgood.index]['boro_int_code']\n",
    "xdata=(fit3.params.drop('const')*justgood[PTtimerates]).sum(axis=1)\n",
    "#justgood.drop(justgood[Yname].idxmax(),inplace=True)\n",
    "#SI=justgood[justgood['boro_int_code']==5]\n",
    "#NSI=justgood[justgood['boro_int_code']!=5]\n",
    "plt.autoscale(enable=False)\n",
    "linx=np.linspace(xdata.min(),xdata.max())\n",
    "#plt.scatter(NSI[labelx],NSI[Yname],alpha=0.5)\n",
    "#plt.scatter(SI[labelx],SI[Yname],alpha=0.5,color='yellow')\n",
    "plt.scatter(xdata.drop(outliers3),justgood.drop(outliers3)[Yname],alpha=0.4)\n",
    "plt.scatter(xdata.loc[outliers3],justgood.loc[outliers3][Yname],alpha=0.4,color='green')\n",
    "plt.plot(linx,np.exp(linx+fit3.params['const']),color='red',alpha=0.8)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(xdata.min(),xdata.max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel('fitted public transit time based projection')\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "#plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "highleverage3=infframe3[infframe3['hat_diag']>(infframe3['hat_diag'].mean()*3)].index\n",
    "#\"' OR fipscodes = '\".join(highleverage.tolist())\n",
    "highleverage3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#justgood['boro_int_code']=pcfull.loc[justgood.index]['boro_int_code']\n",
    "xdata=(fit3.params.drop('const')*justgood[PTtimerates]).sum(axis=1)\n",
    "#justgood.drop(justgood[Yname].idxmax(),inplace=True)\n",
    "#SI=justgood[justgood['boro_int_code']==5]\n",
    "#NSI=justgood[justgood['boro_int_code']!=5]\n",
    "plt.autoscale(enable=False)\n",
    "linx=np.linspace(xdata.min(),xdata.max())\n",
    "#plt.scatter(NSI[labelx],NSI[Yname],alpha=0.5)\n",
    "#plt.scatter(SI[labelx],SI[Yname],alpha=0.5,color='yellow')\n",
    "plt.scatter(xdata.drop(outliers3|highleverage3),justgood.drop(outliers3|highleverage3)[Yname],alpha=0.4)\n",
    "plt.scatter(xdata.loc[outliers3|highleverage3],justgood.loc[outliers3|highleverage3][Yname],alpha=0.4,color='green')\n",
    "plt.plot(linx,np.exp(linx+fit3.params['const']),color='red',alpha=0.8)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(xdata.min(),xdata.max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel('fitted public transit time based projection')\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "#plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model4=sm.OLS(np.log(justgood.drop(outliers3|highleverage3)[Yname]),sm.add_constant(justgood.drop(outliers3|highleverage3)[PTtimerates],prepend=False))\n",
    "fit4=model4.fit()\n",
    "fit4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#justgood['boro_int_code']=pcfull.loc[justgood.index]['boro_int_code']\n",
    "xdata=(fit4.params.drop('const')*justgood[PTtimerates]).sum(axis=1)\n",
    "#justgood.drop(justgood[Yname].idxmax(),inplace=True)\n",
    "#SI=justgood[justgood['boro_int_code']==5]\n",
    "#NSI=justgood[justgood['boro_int_code']!=5]\n",
    "plt.autoscale(enable=False)\n",
    "linx=np.linspace(xdata.min(),xdata.max())\n",
    "#plt.scatter(NSI[labelx],NSI[Yname],alpha=0.5)\n",
    "#plt.scatter(SI[labelx],SI[Yname],alpha=0.5,color='yellow')\n",
    "plt.scatter(xdata.drop(outliers3|highleverage3),justgood.drop(outliers3|highleverage3)[Yname],alpha=0.4)\n",
    "#plt.scatter(xdata.loc[outliers3|highleverage3],justgood.loc[outliers3|highleverage3][Yname],alpha=0.4,color='green')\n",
    "plt.plot(linx,np.exp(linx+fit4.params['const']),color='red',alpha=0.8)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(xdata.min(),xdata.max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel('fitted public transit time based projection')\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "#plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(xdata.drop(outliers3|highleverage3),fit4.resid_pearson,alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set([1,3,4,5,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nout=100\n",
    "loutliers=[]\n",
    "lhighlev=[]\n",
    "\n",
    "while nout>10:\n",
    "    lmodel=sm.OLS(np.log(justgood.drop(loutliers+lhighlev)[Yname]),sm.add_constant(justgood.drop(loutliers+lhighlev)[PTtimerates],has_constant='add',prepend=False))\n",
    "    lfit=lmodel.fit()\n",
    "    #lfit.summary()\n",
    "    linfframe=outliers_influence.OLSInfluence(lfit).summary_frame()\n",
    "    tempouts=linfframe[np.abs(linfframe['student_resid'])>3].index.tolist()\n",
    "    temphigh=(linfframe[linfframe['hat_diag']>(3*linfframe['hat_diag'].mean())].index.tolist())\n",
    "    nout=len(temphigh+list(set(tempouts)-set(temphigh)))\n",
    "    print(nout)\n",
    "    loutliers.extend(tempouts)\n",
    "    lhighlev.extend(temphigh)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(lhighlev+list(set(loutliers)-set(lhighlev))))\n",
    "lfit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#justgood['boro_int_code']=pcfull.loc[justgood.index]['boro_int_code']\n",
    "xdata=(lfit.params.drop('const')*justgood[PTtimerates]).sum(axis=1)\n",
    "#justgood.drop(justgood[Yname].idxmax(),inplace=True)\n",
    "#SI=justgood[justgood['boro_int_code']==5]\n",
    "#NSI=justgood[justgood['boro_int_code']!=5]\n",
    "plt.autoscale(enable=False)\n",
    "linx=np.linspace(xdata.min(),xdata.max())\n",
    "#plt.scatter(NSI[labelx],NSI[Yname],alpha=0.5)\n",
    "#plt.scatter(SI[labelx],SI[Yname],alpha=0.5,color='yellow')\n",
    "plt.scatter(xdata.loc[lhighlev],justgood.loc[lhighlev][Yname],alpha=0.4,color='green')\n",
    "plt.scatter(xdata.loc[loutliers],justgood.loc[loutliers][Yname],alpha=0.4,color='red')\n",
    "plt.scatter(xdata.drop(loutliers+lhighlev),justgood.drop(loutliers+lhighlev)[Yname],alpha=0.4)\n",
    "\n",
    "plt.plot(linx,np.exp(linx+lfit.params['const']),color='red',alpha=0.8)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(xdata.min(),xdata.max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel('fitted public transit time based projection')\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "#plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing time separately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timeweights=pd.DataFrame({'labels':PTtimerates,'weights':[5,12,17,22,27,32,39.5,52,80]}).set_index('labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PTtimerates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcfull['approx_sub_ctime']=((timeweights['weights']*pcfull[PTtimerates]).sum(axis=1)/pcfull['MOGE081'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsub=pcfull[(pcfull['nondrivercomrat']<=0.8)&(pcfull['boro_int_code']!=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelx='approx_sub_ctime'\n",
    "justgood=bsub[[labelx,Yname]]\n",
    "justgood.replace(0.0,np.nan,inplace=True)\n",
    "justgood.replace(np.inf,np.nan,inplace=True)\n",
    "justgood.replace(-np.inf,np.nan,inplace=True)\n",
    "justgood.dropna(inplace=True)\n",
    "\n",
    "plt.autoscale(enable=False)\n",
    "xdata=justgood[labelx]\n",
    "plt.scatter(xdata,justgood[Yname],alpha=0.4)\n",
    "\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(xdata.min(),xdata.max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "#plt.xlabel('fitted public transit time based projection')\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "#plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelx='approx_sub_ctime'\n",
    "justgood=bsub[[labelx,Yname]]\n",
    "justgood.replace(0.0,np.nan,inplace=True)\n",
    "justgood.replace(np.inf,np.nan,inplace=True)\n",
    "justgood.replace(-np.inf,np.nan,inplace=True)\n",
    "justgood.dropna(inplace=True)\n",
    "\n",
    "plt.autoscale(enable=False)\n",
    "xdata=1/justgood[labelx]\n",
    "plt.scatter(xdata,justgood[Yname],alpha=0.4)\n",
    "\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(xdata.min(),xdata.max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "#plt.xlabel('fitted public transit time based projection')\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "#plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "justgood=bsub[bsub['approx_sub_ctime']!=60.0][['MOGE081','approx_sub_ctime',Yname]]\n",
    "justgood.replace(0.0,np.nan,inplace=True)\n",
    "justgood.replace(np.inf,np.nan,inplace=True)\n",
    "justgood.replace(-np.inf,np.nan,inplace=True)\n",
    "justgood.dropna(inplace=True)\n",
    "justgood['sub_ctime_inv']=1/justgood['approx_sub_ctime']\n",
    "modeltime=sm.OLS(np.log(justgood[Yname]),sm.add_constant(justgood[['MOGE081','sub_ctime_inv']],prepend=False))\n",
    "timefit=modeltime.fit()\n",
    "timefit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#justgood['boro_int_code']=pcfull.loc[justgood.index]['boro_int_code']\n",
    "xdata=(timefit.params.drop('const')*justgood[['MOGE081','sub_ctime_inv']]).sum(axis=1)\n",
    "#justgood.drop(justgood[Yname].idxmax(),inplace=True)\n",
    "#SI=justgood[justgood['boro_int_code']==5]\n",
    "#NSI=justgood[justgood['boro_int_code']!=5]\n",
    "plt.autoscale(enable=False)\n",
    "linx=np.linspace(xdata.min(),xdata.max())\n",
    "#plt.scatter(NSI[labelx],NSI[Yname],alpha=0.5)\n",
    "#plt.scatter(SI[labelx],SI[Yname],alpha=0.5,color='yellow')\n",
    "#plt.scatter(xdata.loc[lhighlev],justgood.loc[lhighlev][Yname],alpha=0.4,color='green')\n",
    "#plt.scatter(xdata.loc[loutliers],justgood.loc[loutliers][Yname],alpha=0.4,color='red')\n",
    "plt.scatter(xdata,justgood[Yname],alpha=0.4)\n",
    "\n",
    "plt.plot(linx,np.exp(linx+timefit.params['const']),color='red',alpha=0.8)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(xdata.min(),xdata.max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel('fitted public transit time based projection')\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "#plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cartimeweights.index.to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writenewlotsofdatacolumn(df,sqlengine,newcolumnname,newcolumntype,sqlnewname='the_same',fipscodes='index'):\n",
    "    if sqlnewname=='the_same':\n",
    "        sqlnewname=newcolumnname\n",
    "    s=sqla.text('ALTER TABLE lotsofdata ADD COLUMN ' + sqlnewname +' '+newcolumntype)\n",
    "    conn=engine.connect()\n",
    "    conn.execute(s)\n",
    "    metadata=sqla.MetaData()\n",
    "    borotest=sqla.Table('lotsofdata',metadata,autoload=True,autoload_with=engine)\n",
    "    smt=borotest.update().\\\n",
    "    where(borotest.c.fipscodes==sqla.bindparam('a_code')).\\\n",
    "    values({sqlnewname:sqla.bindparam('a_'+newcolumnname)})\n",
    "    if fipscodes=='index':\n",
    "        df['fipskey']=df.index.to_series()\n",
    "        fipscodes='fipskey'\n",
    "    dlist=df[[fipscodes,newcolumnname]].\\\n",
    "    rename(columns={fipscodes:'a_code',newcolumnname:'a_'+newcolumnname}).\\\n",
    "    to_dict(orient='records')\n",
    "    conn.execute(smt,dlist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcfull['approx_sub_ctime'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writenewlotsofdatacolumn(pcfull,engine,'approx_sub_ctime','double precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cartimerates=['MOGE0'+str(i) for i in xrange(12,21)]\n",
    "cartimeweights=pd.DataFrame({'labels':cartimerates,'weights':[5,12,17,22,27,32,39.5,52,80]}).set_index('labels')\n",
    "pcfull['approx_car_ctime']=((cartimeweights['weights']*pcfull[cartimerates]).sum(axis=1)/pcfull['MOGE011'])\n",
    "pcfull['approx_car_ctime'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testmod=sm.OLS(np.log(justgood[Yname]),sm.add_constant(xdata,prepend=False))\n",
    "testmod=testmod.fit()\n",
    "testmod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "influence=outliers_influence.OLSInfluence(fit4)\n",
    "\n",
    "infframe4=influence.summary_frame()\n",
    "\n",
    "outliers4=infframe4[np.abs(infframe4['student_resid'])>3].index\n",
    "#print(\"fipscodes = '\"+\"' OR fipscodes = '\".join(outliers3.tolist())+\"'\")\n",
    "highleverage4=infframe4[infframe4['hat_diag']>(infframe4['hat_diag'].mean()*3)].index\n",
    "#\"' OR fipscodes = '\".join(highleverage.tolist())\n",
    "highleverage4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#justgood['boro_int_code']=pcfull.loc[justgood.index]['boro_int_code']\n",
    "xdata=(fit4.params.drop('const')*justgood[PTtimerates]).sum(axis=1)\n",
    "#justgood.drop(justgood[Yname].idxmax(),inplace=True)\n",
    "#SI=justgood[justgood['boro_int_code']==5]\n",
    "#NSI=justgood[justgood['boro_int_code']!=5]\n",
    "plt.autoscale(enable=False)\n",
    "linx=np.linspace(xdata.min(),xdata.max())\n",
    "#plt.scatter(NSI[labelx],NSI[Yname],alpha=0.5)\n",
    "#plt.scatter(SI[labelx],SI[Yname],alpha=0.5,color='yellow')\n",
    "plt.scatter(xdata.drop(outliers3|highleverage3|outliers4|highleverage4),justgood.drop(outliers3|highleverage3|outliers4|highleverage4)[Yname],alpha=0.4)\n",
    "plt.scatter(xdata.loc[outliers4|highleverage4],justgood.loc[outliers4|highleverage4][Yname],alpha=0.4,color='green')\n",
    "plt.plot(linx,np.exp(linx+fit4.params['const']),color='red',alpha=0.8)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(xdata.min(),xdata.max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel('fitted public transit time based projection')\n",
    "plt.ylabel('2013 dropoffs per capita')\n",
    "#plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#np.log(Ysub[bsub[labelx]>0])/np.log(10)\n",
    "labelx=pcfeaturescores.index[1]\n",
    "plt.scatter(pcfull[(pcfull[labelx]>0)&(pcfull[Yname]>0)][labelx],np.log(pcfull[(pcfull[labelx]>0)&(pcfull[Yname]>0)][Yname])/np.log(10),alpha=0.5)\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(bsub[bsub[labelx]>0][labelx].min(),bsub[bsub[labelx]>0][labelx].max())\n",
    "plt.xlabel(labelx)\n",
    "plt.ylabel(\"log \"+Yname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcfeaturescores.iloc[:-105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I imagine that lots of these are highly correlated. Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usedind=pcfeaturescores.iloc[:10].index.append(pd.Index([Yname]))\n",
    "corr_matrix = np.corrcoef(bsub[usedind].T)\n",
    "sm.graphics.plot_corr(corr_matrix, xnames=usedind.tolist(),cmap=plt.cm.get_cmap('viridis'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we probably could look at 'MOGE085':'Public transportation (excluding taxicab): Streetcar or trolley car (carro publico in Puerto Rico), subway or elevated: 20 to 24 minutes' and 'MOGE088': 'Public transportation (excluding taxicab): Streetcar or trolley car (carro publico in Puerto Rico), subway or elevated: 35 to 44 minutes' and find something usefull, but the rest are very highly correlated. This will essentially be looking at the ratio of people in a given tract who ride the subway, weighted a little bit by the amount of time they take. After this we might have to dig into the list by correlation. We have to dig pretty deep into list of features to find unreasonably high p-values, so we should have plenty to work with.\n",
    "\n",
    "Let's see about those two first though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "labelx=pcfeaturescores.index[0]\n",
    "plt.scatter(bsub[bsub[labelx]>0][labelx],np.log(Ysub[bsub[labelx]>0])/np.log(10),alpha=0.5)\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(bsub[bsub[labelx]>0][labelx].min(),bsub[bsub[labelx]>0][labelx].max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myscatter(df,labelx,labely,datadict):\n",
    "    plt.autoscale(enable=True, axis='both', tight=True)\n",
    "    plt.scatter(df[labelx],df[labely],alpha=0.5)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.title(datadict[labely]+\" vs \"+datadict[labelx])\n",
    "    plt.ylabel(labely)\n",
    "    plt.xlabel(labelx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bsub['MRUE001']=full[(pcfull['nondrivercommuterrat']<comd)]['MRUE001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ysub.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcfeaturescores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codebookdict[pcfeaturescores.iloc[:10].index].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "labelx=pcfeaturescores.index[0]\n",
    "plt.scatter(bsub[bsub[labelx]>0][labelx],np.log(Ysub[bsub[labelx]>0])/np.log(10),alpha=0.5)\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(bsub[bsub[labelx]>0][labelx].min(),bsub[bsub[labelx]>0][labelx].max())\n",
    "plt.xlabel(labelx)\n",
    "plt.ylabel(\"log \"+Yname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "labelx=pcfeaturescores.index[8]\n",
    "plt.scatter(bsub[bsub[labelx]>0][labelx],np.log(Ysub[bsub[labelx]>0])/np.log(10),alpha=0.5)\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(bsub[bsub[labelx]>0][labelx].min(),bsub[bsub[labelx]>0][labelx].max())\n",
    "plt.xlabel(labelx)\n",
    "plt.ylabel(\"log \"+Yname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bsub[(bsub[pcfeaturescores.index[0]]==0.0)&(bsub[pcfeaturescores.index[3]]!=0.0)]['abridged2013ycdrpoffpc'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get some reasonable data, we're going to have to modify our data a bit. There is a bunch of estimate where the census the estimates that exactly zero people did said thing, so I'm going to change those to just 1 so we don't have a bunch of infinites when we take the log, as it looks like a logorithmic fit is probably best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "justgood.replace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(bsub[Yname]==0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcfull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "((1.0/bsub[justgood[featindex[0]]==0.0]['totalpopulation'])==0.0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(justgood[featindex[0]]==0.0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "justgood[justgood[i]==0.0][i]=(1.0/bsub[justgood[i]==0.0]['totalpopulation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(justgood[featindex[0]].replace(to_replace=0.0,value=1.0/bsub['totalpopulation'])==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codebookdict[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "labelx=featindex[1]\n",
    "plt.scatter(justgood[labelx],np.log(justgood[Yname])/np.log(10),alpha=0.5)\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.xlabel(labelx)\n",
    "plt.ylabel(\"log \"+Yname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "labelx=pcfeaturescores.index[0]\n",
    "plt.scatter(justgood[labelx],np.log(justgood[Yname])/np.log(10),alpha=0.5)\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.xlabel(labelx)\n",
    "plt.ylabel(\"log \"+Yname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featindex=[pcfeaturescores.index[0],pcfeaturescores.index[8]]\n",
    "justgood=bsub[featindex+[Yname]]\n",
    "justgood.replace(0.0,np.nan,inplace=True)\n",
    "justgood.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "justgood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#featindex=[pcfeaturescores.index[0],pcfeaturescores.index[3]]\n",
    "model=sm.OLS(np.log(justgood['abridged2013ycdrpoffpc']),sm.add_constant(np.log(justgood[featindex]),prepend=False))\n",
    "fit=model.fit()\n",
    "fit.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#featindex=[pcfeaturescores.index[0],pcfeaturescores.index[3]]\n",
    "model=sm.OLS(np.log(bsub[Yname]),sm.add_constant(bsub['MOGE081'],prepend=False))\n",
    "fit=model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks to me like this data might actually be better fit with some clustering. It appears that we have two clusters, on with low subway commuters, and one that looks like there isn't much correlation with the number of subway commuters. I would guess that if we looked at each cluster seperately, the p-value would be pretty high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(np.array([justgood[labelx],np.log(justgood[Yname])])).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "justgood[[labelx,Yname]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmodel=cluster.KMeans(n_clusters=3 )\n",
    "justgood['cluster']=kmodel.fit_predict((np.array([justgood[labelx],np.log(justgood[Yname])])).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "justgood['cluster'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.autoscale(enable=False)\n",
    "linx=np.linspace(justgood[labelx].min(),justgood[labelx].max())\n",
    "cllinx=np.linspace(0.0,0.1)\n",
    "plt.scatter(justgood[labelx],justgood[Yname],alpha=0.1,c=justgood['cluster'],cmap=plt.cm.get_cmap('jet'))\n",
    "plt.plot(linx,np.exp(fit.params[labelx]*linx+fit.params['const']),color='red',alpha=0.1)\n",
    "plt.plot(cllinx,10**(-16*cllinx-1.4),color='green',alpha=0.8)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel(labelx)\n",
    "plt.ylabel(\"log \"+Yname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "justgood['mydivision']=np.sign(justgood[Yname]-10**(-16*justgood['MOGE081']-1.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.autoscale(enable=False)\n",
    "linx=np.linspace(justgood[labelx].min(),justgood[labelx].max())\n",
    "cllinx=np.linspace(0.0,0.1)\n",
    "plt.scatter(justgood[labelx],justgood[Yname],alpha=0.5,c=justgood['mydivision'],cmap=plt.cm.get_cmap('jet'))\n",
    "#plt.plot(linx,np.exp(fit.params[labelx]*linx+fit.params['const']),color='red',alpha=0.1)\n",
    "plt.plot(cllinx,10**(-16*cllinx-1.4),color='black',alpha=0.8)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel(labelx)\n",
    "plt.ylabel(\"log \"+Yname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "justgood['mydivision'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1=sm.OLS(np.log(justgood[justgood['mydivision']==-1][Yname]),sm.add_constant(justgood[justgood['mydivision']==-1]['MOGE081'],prepend=False))\n",
    "fit1=model1.fit()\n",
    "fit1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2=sm.OLS(np.log(justgood[justgood['mydivision']==1][Yname]),sm.add_constant(justgood[justgood['mydivision']==1]['MOGE081'],prepend=False))\n",
    "fit2=model2.fit()\n",
    "fit2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit2.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.autoscale(enable=False)\n",
    "linx=np.linspace(justgood[labelx].min(),justgood[labelx].max())\n",
    "cllinx=np.linspace(0.0,0.1)\n",
    "plt.scatter(justgood[labelx],justgood[Yname],alpha=0.5,c=justgood['mydivision'],cmap=plt.cm.get_cmap('jet'))\n",
    "plt.plot(linx,np.exp(fit2.params[labelx]*linx+fit2.params['const']),color='red',alpha=0.8)\n",
    "#plt.plot(cllinx,10**(-16*cllinx-1.4),color='black',alpha=0.8)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel(labelx)\n",
    "plt.ylabel(\"log \"+Yname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value for the larger high MOGE081 cloud is way lower than I expected, but the fit is still pretty abysmal even if there is a bit of a pattern, with an $R^2$ of 0.19. This data is also very far from ideal data for OLS. I'm looking at it and I see a high density cluster that I imagine has a high p-value on its own, with a bunch of high leverage points on the margins that are driving the OLS fit. \n",
    "\n",
    "The other cluster does have a really high p-value, so I might be able to try to select out that chunk and represent it by the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myscatter(bsub,pcfeaturescores.index[0],Yname,codebookdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codebookdict[pcfeaturescores.iloc[:10].index].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full=pd.read_sql_query('SELECT '+columnstring + ' FROM lotsofdata;',engine).set_index('fipscodes')\n",
    "full=full[full['totalpopulation']>=1000]\n",
    "Yname='abridged2013ycdrpoffpc'\n",
    "dropoffitems=['abridged2013ycdrpoffpc','counts','abridged2013ycdrpoff']\n",
    "full.drop([i for i in dropoffitems if i is not Yname],axis=1,inplace=True)\n",
    "full.replace(np.inf, np.nan,inplace=True)\n",
    "full.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureselect=feature_selection.SelectKBest(feature_selection.f_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureselect.fit(full.drop(Yname,axis=1),full[Yname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featurescores=pd.Series(featureselect.scores_)\n",
    "featurescores.index=full.drop(Yname,axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featurescores.sort_values(ascending=True,inplace=True)\n",
    "featurescores.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featurescores.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codebookdict[featurescores.index.tolist()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full.plot.scatter(featurescores.index.tolist()[0],Yname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcfull=full\n",
    "pcfull.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcfull.replace({'totalpopulation':{0:np.nan}},inplace=True)\n",
    "pcfull.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y=pcfull['abridged2013ycdrpoffpc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcfull=full.drop(['totalpopulation'],axis=1).divide(full['totalpopulation'],axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureselect=feature_selection.SelectKBest(feature_selection.f_regression)\n",
    "featureselect.fit(pcfull,full['abridged2013ycdrpoffpc'])\n",
    "pcfeaturescores=pd.Series(featureselect.scores_)\n",
    "pcfeaturescores.index=pcfull.columns\n",
    "pcfeaturescores.sort_values(ascending=True).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query('SELECT '+ '\"MOJE007\",\"counts\"'+ ' FROM lotsofdata, WHERE totalpopulation>=1000',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcpvals=pd.Series(featureselect.pvalues_)\n",
    "pcpvals.index=pcfull.drop(Yname,axis=1).columns\n",
    "pcpvals.sort_values(ascending=True,inplace=True)\n",
    "pcpvals.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codebookdict[pcpvals.iloc[:10].index].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureselect=feature_selection.SelectKBest(feature_selection.f_regression)\n",
    "pcfull.drop_duplicates(inplace=True)\n",
    "pcfull=pcfull.T.drop_duplicates().T\n",
    "featureselect.fit(pcfull.drop(Yname,axis=1),Y)\n",
    "pcpvals=pd.Series(featureselect.pvalues_)\n",
    "pcpvals.index=pcfull.drop(Yname,axis=1).columns\n",
    "pcpvals.sort_values(ascending=True,inplace=True)\n",
    "#pcpvals.iloc[:10]\n",
    "codebookdict[pcpvals.iloc[:10].index].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcpvals.index.get_loc('nondrivercommuterrat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(codebookdict[pcfeaturescores.index[3]])\n",
    "pcfull.plot.scatter(pcfeaturescores.index[3],Yname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codebookdict[pcfeaturescores.iloc[:10].index].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usedind=pcfeaturescores.iloc[:10].index.append(pd.Index([Yname]))\n",
    "corr_matrix = np.corrcoef(bsub[usedind].T)\n",
    "sm.graphics.plot_corr(corr_matrix, xnames=usedind.tolist(),cmap=plt.cm.get_cmap('viridis'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bsub[PTtimerates].multiply(bsub['totalpopulation'],axis='index').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "justgood.sum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit3.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(pcfull['nondrivercommuterrat']<=0.8).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "xdata=(fit3.params.drop('const')*justgood).sum(axis=1)\n",
    "#justgood.drop(justgood[Yname].idxmax(),inplace=True)\n",
    "#SI=justgood[justgood['boro_int_code']==5]\n",
    "#NSI=justgood[justgood['boro_int_code']!=5]\n",
    "plt.autoscale(enable=False)\n",
    "#linx=np.linspace(justgood[labelx].min(),justgood[labelx].max())\n",
    "#plt.scatter(NSI[labelx],NSI[Yname],alpha=0.5)\n",
    "#plt.scatter(SI[labelx],SI[Yname],alpha=0.5,color='yellow')\n",
    "plt.scatter(xdata,bsub[Yname],alpha=0.65,c=bsub['nondrivercommuterrat'],cmap=plt.cm.get_cmap('viridis'))\n",
    "#plt.plot(linx,np.exp(fit.params[labelx]*linx+fit.params['const']),color='red',alpha=0.8)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(xdata.min(),xdata.max())\n",
    "plt.ylim(bsub[Yname].min(),bsub[Yname].max())\n",
    "#plt.xlabel(labelx)\n",
    "plt.ylabel(\"log \"+Yname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PTtimerates+[Yname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcfull[Yname].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "['MOGE0'+str(i) for i in xrange(82,91)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'MOGE090'\n",
    "codebookdict['MOGE082']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "justgood[labelx].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bsub[['nondrivercomrat','nondrivercommuterrat']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bsub['nondrivercommuterrat']/bsub['totalpopulation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bsub[bsub['nondrivercommuterrat']>0.8].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "labelx=pcfeaturescores.index[9]\n",
    "labelc=pcfeaturescores.index[8]\n",
    "justgood=bsub[[labelx,Yname,'boro_int_code',labelc]]\n",
    "justgood.replace(np.inf,np.nan,inplace=True)\n",
    "justgood.replace(0.0,np.nan,inplace=True)\n",
    "justgood.dropna(inplace=True)\n",
    "#justgood.drop(justgood[Yname].idxmax(),inplace=True)\n",
    "#SI=justgood[justgood['boro_int_code']==5]\n",
    "#NSI=justgood[justgood['boro_int_code']!=5]\n",
    "plt.autoscale(enable=False)\n",
    "linx=np.linspace(justgood[labelx].min(),justgood[labelx].max())\n",
    "#plt.scatter(NSI[labelx],NSI[Yname],alpha=0.5)\n",
    "#plt.scatter(SI[labelx],SI[Yname],alpha=0.5,color='yellow')\n",
    "plt.scatter(justgood[labelx],justgood[Yname],c=justgood[labelc],alpha=0.4)\n",
    "#plt.plot(linx,np.exp(fit.params[labelx]*linx+fit.params['const']),color='red',alpha=0.8)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "#plt.ylim(0,25)\n",
    "#plt.autoscale(enable=True, axis='both', tight=True)\n",
    "#plt.axis('tight')\n",
    "plt.xlim(justgood[labelx].min(),justgood[labelx].max())\n",
    "plt.ylim(justgood[Yname].min(),justgood[Yname].max())\n",
    "plt.xlabel(labelx)\n",
    "plt.ylabel(\"log \"+Yname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
